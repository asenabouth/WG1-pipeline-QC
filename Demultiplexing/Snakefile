#!/usr/local/envs/py36/bin python3

import os
import sys
import pandas as pd
from glob import glob
import subprocess
import shutil


### Extract variables from configuration file for use within the rest of the pipeline
input_dict = config["inputs"]
output_dict = config["outputs"]
ref_dict = config["refs"]
popscle_dict = config["popscle"]
popscle_extra_dict = config["popscle_extra"]
souporcell_dict = config["souporcell"]
souporcell_extra_dict = config["souporcell_extra"]
DoubletDetection_dict = config["DoubletDetection"]
DoubletDetection_manual_dict = config["DoubletDetection_manual"]
DoubletDetection_extra_dict = config["DoubletDetection_extra"]
scrublet_dict = config["scrublet"]
scrublet_manual_dict = config["scrublet_manual"]
scrublet_extra_dict = config["scrublet_extra"]
scds_dict = config["scds"]
CombineResults_dict = config["CombineResults"]


### Copy necessary files from singularity image to outdir
## create hidden folder to hold files from image that are necessary
pipeline_dir = output_dict["output_dir"] + "/.demultiplexing_pipeline/""
if (os.path.exists(pipeline_dir)):
    shutil.rmtree(pipeline_dir)

os.mkdir(pipeline_dir)

## mods
out_mods = pipeline_dir + "/.mods/"
os.mkdir(out_mods)
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/mods/prepareArguments.py", out_mods])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/mods/read10x.py", out_mods])
sys.path.append(out_mods) 
import prepareArguments

## includes
out_inlcudes = pipeline_dir + "/.includes/"
if (os.path.exists(out_inlcudes)):
    shutil.rmtree(out_inlcudes)

os.mkdir(out_inlcudes)
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_popscle.smk", out_inlcudes])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_souporcell.smk", out_inlcudes])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_scrublet.smk", out_inlcudes])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_scds.smk", out_inlcudes])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_DoubletDetection.smk", out_inlcudes])
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/includes/Snakefile_CombineResults.smk", out_inlcudes])

## files
subprocess.call(["singularity", "exec", input_dict["singularity_image"], "cp", "/opt/WG1-pipeline-QC/Demultiplexing/Mitochondrial_genes.txt", pipeline_dir])

### Use prepareArguments.py script to retrieve exact directories of single cell files
scrnaseq_libs_df = prepareArguments.get_scrnaseq_dirs(config)
scrnaseq_libs_df.to_csv(os.path.join(output_dict["output_dir"],'file_directories.txt'), sep = "\t", index = False)


### Get list of pools to process
samples = pd.read_csv(input_dict["samplesheet_filepath"], sep = "\t")
samples.columns = ["Pool", "N"]


### If the scrublet_check output is present => all the contents are there that are needed to move past 
if os.path.exists(output_dict["output_dir"] + "/scrublet/scrublet_check.done"):
    scrublet_decisions = pd.read_csv(output_dict["output_dir"] + "/manual_selections/scrublet_gene_pctl.txt", sep = "\t")

### Includes
include: out_inlcudes + "Snakefile_popscle.smk"
include: out_inlcudes + "Snakefile_souporcell.smk"
include: out_inlcudes + "Snakefile_scrublet.smk"
include: out_inlcudes + "Snakefile_scds.smk"
include: out_inlcudes + "Snakefile_DoubletDetection.smk"
include: out_inlcudes + "Snakefile_CombineResults.smk"


demuxlet_files = []
demuxlet_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/demuxlet_results.txt",  pool=samples.Pool))

souporcell_files = []
souporcell_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/souporcell_results.txt", pool=samples.Pool))
souporcell_files.append(expand(output_dict["output_dir"] + "/{pool}/souporcell/Individual_genotypes_subset.vcf.gz", pool=samples.Pool))

scds_files = []
scds_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/scds_results.txt", pool=samples.Pool))

### the scrublet files that will be run are dependent on user inputs in the yaml file
scrublet_files = []
scrublet_files.append(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv")
if os.path.exists(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv"):
    scrublet_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv", sep = "\t")
    if scrublet_selection["scrublet_Percentile"].count() == len(scrublet_selection):
        scrublet_selection["scrublet_Percentile"] = scrublet_selection["scrublet_Percentile"].astype(int)
        scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/{pctl}_scrublet_results.txt", zip, pool=scrublet_selection.Pool, pctl = scrublet_selection.scrublet_Percentile))
    elif scrublet_selection["scrublet_Percentile"].count() != len(scrublet_selection):
        if scrublet_manual_dict["run_scrublet_manual"] == False:
            scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/default_run_variables.txt", pool = samples.Pool, pctl = scrublet_dict["percentile"]))
        elif scrublet_manual_dict["run_scrublet_manual"] == True:
            scrublet_files.append(expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/manual_rerun_variables.txt",zip, pool = scrublet_manual_dict["scrublet_manual_threshold_pools"], pctl = scrublet_manual_dict["scrublet_manual_threshold_percentiles"]))
            ### remove the files to force the rule to run if still needing to rerun (will only happen if manual selections aren't filled in all the way)
            for f in expand(output_dict["output_dir"] + "/{pool}/scrublet_{pctl}/manual_rerun_variables.txt",zip, pool = scrublet_manual_dict["scrublet_manual_threshold_pools"], pctl = scrublet_manual_dict["scrublet_manual_threshold_percentiles"]):
                fname = f.rstrip() 
                if os.path.isfile(fname): 
                    os.remove(fname)

DoubletDetection_files = []
DoubletDetection_files.append(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv")
if os.path.exists(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv"):
    DoubletDetection_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv", sep = "\t")
    if len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) == len(DoubletDetection_selection):
        DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/DoubletDetection_results.txt", pool=DoubletDetection_selection.Pool))
    elif len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) != len(DoubletDetection_selection):
        if DoubletDetection_manual_dict["run_DoubletDetection_manual"] == False:
            DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/default_run_variables.txt", pool = samples.Pool))
        elif DoubletDetection_manual_dict["run_DoubletDetection_manual"] == True:
            DoubletDetection_files.append(expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/manual_rerun_variables.txt", pool = DoubletDetection_manual_dict["DoubletDetection_manual_pools"]))
            ### remove the files to force the rule to run if still needing to rerun (will only happen if manual selections aren't filled in all the way)
            for f in expand(output_dict["output_dir"] + "/{pool}/DoubletDetection/manual_rerun_variables.txt", pool = DoubletDetection_manual_dict["DoubletDetection_manual_pools"]):
                fname = f.rstrip() 
                if os.path.isfile(fname): 
                    os.remove(fname)


combined_files = []
if os.path.exists(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv") and os.path.exists(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv"):
    scrublet_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/scrublet/scrublet_percentile_manual_selection.tsv", sep = "\t")
    DoubletDetection_selection = pd.read_csv(output_dict["output_dir"] + "/manual_selections/DoubletDetection/DoubletDetection_manual_selection.tsv", sep = "\t")
    if scrublet_selection["scrublet_Percentile"].count() == len(scrublet_selection) and len(DoubletDetection_selection[DoubletDetection_selection['DoubletDetection_PASS_FAIL'].astype(str).str.contains('PASS', na=False)]) == len(DoubletDetection_selection):
        combined_files.append(expand(output_dict["output_dir"] + "/{pool}/CombinedResults/Final_Assignments_demultiplexing_doublets.txt", pool = samples.Pool))
        combined_files.append(output_dict["output_dir"] + "/QC_figures/UMI_vs_Genes_QC_scatter.png")


rule all:
    input:
        demuxlet_files,
        souporcell_files,
        scds_files,
        scrublet_files,
        DoubletDetection_files,
        combined_files
